Notes on using MQTT with O2.
Roger Dannenberg
May 2020

MQTT is a publish subscribe protocol for IOT. It is interesting mainly
because there are servers on the web that anyone can use, at least for
now. So MQTT is sort of a new Internet service -- now, in addition to
delivering messages, the Internet offers publish/subscribe services
for message routing.

MQTT might not be the best protocol, and it might not survive in the
long run, or it might be so successful that free servers are not
possible to maintain. An alternative is IRC, which could be used even
if it was really meant for human-human communication.

In addition, MQTT can *store* data so that when you subscribe to a
topic you get the last published value for that topic. This makes MQTT
a free and open key-value store service.

MQTT also has LWT messages that can announce when a process
disconnects from the server, which is useful to mimic TCP hangup
functionality. 

After considering more complicated schemes, it seems that MQTT can
simply replace the O2 hub protocol, so if you are on the internet, 
you can just use MQTT. 

If you use O2lite, you need LAN discovery and
unless you put MQTT into the O2lite client, you need to keep
discovery. So MQTT will be an add-on for non-local networks, not
a replacement for discovery in situations where there is Internet
access.

o2_mqtt_enable(const char *broker) sets up a connection to the MQTT
broker and subscribes to the topics O2-<ensemblename>/disc and
O2-<ensemble>/<public ip>:<local ip>:<port>. Then, send public IP and
local IP to the /disc topic. Other processes will also send to the
/disc topic, so every process will discover every other process soon
after it connects to the broker.

Subscribe to:
    O2-ens/disc
    O2-ens/@pip:iip:port
Discovery message:
    topic: O2-ens/disc, payload: @pip:iip:port:udpport/dy/vers
Clock sync message (when a process gets clock sync):
    topic: O2-ens/disc, payload: @pip:iip:port:udpport/cs/vers
Send O2 message via MQTT:
    topic: O2-ens/@pip:iip:port, payload: an_O2_message_starting_with_
                                        _the_misc_field_(after_length)

Do not use the *store* feature so that when you crash, others will not
"discover" a stale address. However, when you reboot, everyone already
in the application will get the new correct address. Is there a race
condition that could allow two processes connecting to the broker to
miss each other's /disc messages? Assume messages from one client are
handled serially. If we assume the subcriptions are committed before
the subsequent publish is allowed to take place, there is no race.

There is, however, an interesting race where both processes discover
each other at the same time, so that each initiates a protocol to
contact the other. Contacts and discoveries are designed to be
idempotent so that no harm is done.

Because O2 discovery messages (/_o2/dy) are tightly coupled to setting
up TCP connections and associating sockets with O2 process names, we
implement an entirely separate MQTT discovery protocol as follows:

When a process initializes, it subscribes to O2-<ensemblename>/disc
and and publishes it's name to the same topic. Whenever a name arrives
on this topic and the name is unknown, the process creates a local
service with the name and tag MQTT_NOCLOCK, and "connects" to it by
sending an O2 message with address "!_o2/mqtt/dy", type "s",
containing the name of the sender. This has the same effect as an
O2-<ensemblename>/disc message except the message is sent to a
particular process instead of all processes. If the sender is not
known, it is created as a service with an MQTT_NOCLOCK tag and the
usual clock status and service info messages are sent.

It is possible to discover a process through MQTT that can be
connected directly, so before sending the "!_o2/mqtt/dy" message, the
following decision tree is followed, and things revert to normal
discovery if MQTT can be avoided:

CASE 1: the incoming message has the same public IP and internal IP.
Assume the process is not behind NAT (it's possible that the LAN
behind NAT uses the same IP address as the public address, but it
seems very unlikely and non-standard). 

    CASE 1A: You have a lower IP than they do, so you are the client.
    You can connect directly, send a discovery message as if you just
    received an O2_DY_INFO and you are the client.  Let the discovery 
    protocol make the connection. The remote process will become a 
    PROC_NOCLOCK and then a PROC_SYNCED.

    CASE 1B: You have a higher IP than they do, so you are the server. 
         CASE 1B1: Your public and internal IP are the same, so you can 
         receive a connection request. Send a discovery message with 
         O2_DY_CALLBACK to the remote proc.  Let the discovery 
         protocol make the connection. The remote process will 
         become a PROC_NOCLOCK and then a PROC_SYNCED. 

         CASE 1B2: Your public and internal IP are different, so you are 
         the server, but the remote process cannot make a connection 
         because you are behind NAT and can only be accessed via MQTT. 
         Create an MQTT_NOCLOCK connection that will become an 
         MQTT_SYNCED connection. The /publicip:internalip:port service 
         name will map to the MQTT node.  All messages will be sent 
         via MQTT to the topic corresponding to the remote process 
         IP addresses. 

Whatever the remote process, services are sent to !_o2/sv there.

CASE 2: the incoming message has different public IP and internal IP.
Assume the process is behind NAT. Note that you are behind the
same NAT if you have a matching public IP. In that case, it's possible
that broadcasts are disabled so discovery will only occur by MQTT even
though local direct connections can be made after discovery.

    CASE 2A: You have the same Public IP as they do. Assume you are on
         the same local network.
         CASE 2A1: Your IP is higher, so you are the server. Send a 
         discovery message via MQTT with O2_DY_CALLBACK to the remote 
         proc.  Let the discovery protocol make the connection. The 
         remote process will become a PROC_NOCLOCK and then a PROC_SYNCED. 

         CASE 2A2: Your IP is lower, so you are the client. Connect as
         in CASE 1A.

    CASE 2B: You have a lower IP than they do and a different public
         IP. You can only reach via MQTT, so create an MQTT_NOCLOCK
         connection as in CASE 1B2.

    CASE 2C: You have a higher IP than they do, and a different public
         IP, so you are the server.  
         CASE 2C1: Your public and internal IP are the same, so you
         can receive a connection request. Send a discovery message as
         in CASE 2A1.

         CASE 2C2: Your public and internal IP are different, so you are 
         the server, but the remote process cannot make a connection 
         because you are behind NAT and can only be accessed via MQTT. 
         Create an MQTT_NOCLOCK connection as in CASE 1B2.

When a process becomes synchronized, it announces its new status to
all other processes. For remote MQTT processes, we publish only one
message to O2-ens/disc, using publish-subscribe as a form of
broadcast. 

There is only one TCP connection to the MQTT broker, but may be many
processes. The MQTT connection should be shared by all, created by 
o2_mqtt_enable(const char *mqtt_broker), and closed by o2_finish().

There is an MQTT_info associated with this shared connection. It has
a NULL key, whereas every remote MQTT process discovered so far has
an MQTT_info as proxy with a key equal to the remote process name.

When a remote process or service is discovered through MQTT, we need
to set up a service named pip:iip:port that maps to a node
with tag MQTT_NOCLOCK or MQTT_SYNCED. This node should have a pointer
back to the pip:iip:port key so we can find the process name
for the provider of any service, but unlike PROC nodes that have
net_info and udp_address fields for sending messages, these MQTT nodes
will just send messages via the singleton MQTT connection.

For simplicity, we'll use MQTT_info for two purposes:
1. to represent a remote process. Thus, there is one MQTT_info for each
   remote pip:iip:port key. The fds_info pointer on these instances is
   NULL, and they find the network connection via the global mqtt_info.
2. to represent a Net_interface. This unique instance is referenced by
   mqtt_info and its fds_info member points to an Fds_info object,
   which points back as usual through its owner member variable.

To enumerate MQTT processes, since they do not have corresponding
o2n_info structures, we need an array of names. Names are added if we
enter a new name in path_tree, and names are deleted if we remove one
from the path_tree. This is linear in the number of remote processes,
but it is not too common or too expensive since the array size will be
less than 800 bytes if we have 8-byte pointers and up to 100
processes.

When a message is received from the MQTT broker, we get the topic,
which is the receiver's pip:iip:port name, but not the
sender. We need to know the sender, e.g. for a /_cs/cs or /_o2/sv
message. We will add the process name to /_cs/cs messages (it's
already in /_o2/sv). 

Discovery Protocol
------------------
PROCESS 1                  BROKER           PROCESS 2
subscribe ---------------->
publish to O2-ens/disc --->
                                 <--------- subscribe
create proc2 <--------- O2-ens/disc <------ publish to O2-ens/disc
publish --------------> !_o2/mqtt/dy -----> create proc1
publish ------------------ !_o2/sv -------> create services
create services <--------- !_o2/sv <------- publish

Every message to /disc carries a suffix of either /dy or /cs to
convey the clock state. When clock state becomes synchronized,
an immediate discovery message is sent with /cs.

Disconnect Protocol
-------------------
A clean disconnect or shutdown can be accomplished by sending
<name>/bye to O2-ens/disc.

For unannounced disconnects, we use keep-alive messages. These are
broadcast by sending to O2-ens/disc with topic name/dy or name/cs
every 10s. A timeout is associated with each known remote proc, and
expired processes are detected and deleted every 10s.



*********************************************************************
* ================================================================= *
* == everything below this line is obsoleted by the design above == *
* == It's here for reference in case I want to rethink things.   == *
* ================================================================= *
*********************************************************************


Hub Protocol
------------

One use of MQTT with O2 is to communicate a Hub IP address. The Hub
protocol is an alternative to the O2 discovery protocol, especially
for cases where UDP broadcast will not work: either UDP broadcast is
not allowed or the O2 ensemble is not on the same local network. The
problem with hubs is you need to designate a hub and share its IP/port
location with the ensemble.

A good solution is MQTT. The hub can publish its IP/port address to
topic "O2-<ensemblename>/hub" with (ASCII) message of the form
"128.2.100.73:4567", where <ensemblename> is replaced with the actual
ensemble name. The hub should use the "retain" flag so that
subscribers will get the message even if they subscribe after the
message is posted (or if they restart later).

We should create a separate library -- o2mqtt -- to implement this
feature. The API is:
  int o2m_initialize(const char *ensemble_name,
                     const char *broker, int hub_flag);
    Initialize O2 with ensemble_name and discovery disabled. address
    is the domain name or ip address of an MQTT broker. If NULL, then
    the default broker "mqtt.eclipseprojects.io" is used. If hub_flag is
    true, this process is the hub, so it publishes its IP:port address
    to the MQTT broker, using topic O2-<ensemble_name>/hub. The call
    may block to make a TCP connect, but it will not block waiting for
    TCP messages. Instead, you must call o2m_poll() until the hub
    address is published. If hub_flag is false, this process will
    acquire the hub address from MQTT using broker to find the MQTT
    broker and subscribing to the topic O2-<ensemble_name>/hub. This
    call may block to make a TCP connect, but it will not block
    waiting for TCP messages. Instead, you must call o2m_poll() until
    the hub address is acquired.

  int o2m_poll();
    Carry out the MQTT publish or subscribe protocol. This call is
    non-blocking and should be called frequently until the protocol
    completes. Return values are: <0 for an error occurred, 0 for
    no error but not complete, and 1 for protocol completed. It is an
    error to call o2m_poll() before calling o2m_initialize(). After 1 is
    received, you may stop calling o2m_poll() but if you call it
    anyway, it will return another 1 quickly. If o2m_initialize() was
    called with hub_flag != 0, then o2m_poll() publishes to the broker
    and then closes the broker connection and cleans up. If hub_flag
    was 0 (false), then o2m_poll() subscribes, waits for the hub
    address (which may return almost immediately if it was previously
    published), and calls o2_hub() with the hub IP/port address. The
    subscription will remain active so if a new hub address is
    published, o2_hub() will be called again to update O2 with the new
    address.

  int o2m_finish();
    If o2m_initialize() was called with o2_hub == 0, call o2m_finish()
    to close the subscription, sockets, free memory, etc. If o2_hub
    was non-zero and o2m_poll() was called until it returned 1
    (complete), then it is not necessary but not an error to call
    o2m_finish().

O2 Bridge from NAT to NAT
-------------------------

Another use of MQTT is to connect O2 processes where at least one is
on a local area network protected by NAT (network address
translation) and another process is on some other network, which
implies that IP addresses cannot be used to make direct peer-to-peer
connections. A simple way to send O2 messages is via the MQTT broker.
Instead of sending directly to a socket, the sender could send a
binary O2 message to the MQTT topic:
"O2-<ensemble_name>/xxx.xxx.xxx.xxx:port". Every O2 process can then
subscribe to this topic and process incoming messages.

A problem here is that O2 processes use their local IP address as the
process name, so we have to be careful with these addresses. Also, the
general solution must handle the case where we have, say, 3 local area
networks, each with 2 processes, so there are 3 pairs of processes
that communicate directly across their LANs, and all other
communication goes through MQTT. Perhaps an even harder problem is to
have two LANs behind NAT and 2 processes not behind NAT. We want the
possibility that ANY process acts as hub, and only messages that cross
a NAT barrier go through MQTT.

The proposed implementation uses the same optional o2mqtt library
used for hub addresses to forward messages through an MQTT broker.

Let's assume users only use o2mqtt if they have Internet
connections. (Isolated networks can just use O2 discovery. If you need
to bridge across NAT, then you must have Internet access.) So compare
the IP address obtained locally to an IP address from a stun server
(which is a pretty simple request -- we don't need a stun library). If
they differ, then you are behind NAT. If you are behind NAT, assume
every machine on your local network has the same public IP
address. (The local IP address could match some other process on
another local network.)

Let's assume if you want to use MQTT at all, then every process can
use it. And maybe o2_hub() is just a bad idea if you have some
processes that need to bridge NAT. And if you can optimize the case
where no bridge is necessary, then maybe you can simplify by always
enabling bridges when necessary.

So here's an alternative to the hub plan described above:

(Let's use /x to mean "O2-<ensemble_name>/x" to shorten the
names. Every MQTT topic will have "O2-<ensemble_name>" as the top-level
topic.)

Use MQTT directly for all discovery.  Every process "broadcasts" to
topic "/disc", sending its local IP:port and its public IP. The public
IP serves as a network identifier. If you are on the same network, you
can directly message the process using its IP:port. If you are not on
the same network and one of you is behind NAT, then you can message
through MQTT by sending the binary O2 message to
"/<public-ip>:<local-ip>:<local-port>". Note that both IP addresses
and a port are needed to identify a process since we could have two
processes on the same machine (same local-ip, different ports) and two
different networks could reuse the local-ip (same local-ip, different
public-ip). 

Within o2m_poll(), we subscribe to both /disc and
/<public-ip>:<local-ip>:<local-port>. When a /disc message arrrives,
we do the normal thing of making a connection, but now we have a new
connection type: MQTT. We'll have to modify the proc_info structure
and message delivery to send the message either to a socket or through
MQTT. That's about all there is to it.

Under this scheme, processes start with 2-part names, but change names
if they get a different public IP address. When that happens, the
process will send a name-change discovery message to all other
processes, and they will rename and rehash the service entry for the
process.




We add a bridge_flag to o2m_initialize():
  int o2m_initialize(const char *ensemble_name,
                     const char *broker, int hub_flag, int bridge_flag);


    

